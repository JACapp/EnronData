{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enron Data POI Classifier \n",
    "### Jo Anna Capp\n",
    "\n",
    "In the 1990's Enron Corporation was one of the largest.....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set working directory\n",
    "import os\n",
    "os.chdir('D:/Documents/Udacity/IntroMachineLearning/ud120projectsmaster/ud120projectsmaster/UdacityP5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import all packages and modules here\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "import pandas\n",
    "import numpy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from ggplot import *\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['poi']\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the structure of the dataset and check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  146 executives of interest in the Enron dataset\n",
      "There are  18 identified persons of interest within the dataset\n",
      "Data Dictionary Keys:\n",
      "['METTS MARK', 'BAXTER JOHN C', 'ELLIOTT STEVEN', 'CORDES WILLIAM R', 'HANNON KEVIN P', 'MORDAUNT KRISTINA M', 'MEYER ROCKFORD G', 'MCMAHON JEFFREY', 'HORTON STANLEY C', 'PIPER GREGORY F', 'HUMPHREY GENE E', 'UMANOFF ADAM S', 'BLACHMAN JEREMY M', 'SUNDE MARTIN', 'GIBBS DANA R', 'LOWRY CHARLES P', 'COLWELL WESLEY', 'MULLER MARK S', 'JACKSON CHARLENE R', 'WESTFAHL RICHARD K', 'WALTERS GARETH W', 'WALLS JR ROBERT H', 'KITCHEN LOUISE', 'CHAN RONNIE', 'BELFER ROBERT', 'SHANKMAN JEFFREY A', 'WODRASKA JOHN', 'BERGSIEKER RICHARD P', 'URQUHART JOHN A', 'BIBI PHILIPPE A', 'RIEKER PAULA H', 'WHALEY DAVID A', 'BECK SALLY W', 'HAUG DAVID L', 'ECHOLS JOHN B', 'MENDELSOHN JOHN', 'HICKERSON GARY J', 'CLINE KENNETH W', 'LEWIS RICHARD', 'HAYES ROBERT E', 'MCCARTY DANNY J', 'KOPPER MICHAEL J', 'LEFF DANIEL P', 'LAVORATO JOHN J', 'BERBERIAN DAVID', 'DETMERING TIMOTHY J', 'WAKEHAM JOHN', 'POWERS WILLIAM', 'GOLD JOSEPH', 'BANNANTINE JAMES M', 'DUNCAN JOHN H', 'SHAPIRO RICHARD S', 'SHERRIFF JOHN R', 'SHELBY REX', 'LEMAISTRE CHARLES', 'DEFFNER JOSEPH M', 'KISHKILL JOSEPH G', 'WHALLEY LAWRENCE G', 'MCCONNELL MICHAEL S', 'PIRO JIM', 'DELAINEY DAVID W', 'SULLIVAN-SHAKLOVITZ COLLEEN', 'WROBEL BRUCE', 'LINDHOLM TOD A', 'MEYER JEROME J', 'LAY KENNETH L', 'BUTTS ROBERT H', 'OLSON CINDY K', 'MCDONALD REBECCA', 'CUMBERLAND MICHAEL S', 'GAHN ROBERT S', 'MCCLELLAN GEORGE', 'HERMANN ROBERT J', 'SCRIMSHAW MATTHEW', 'GATHMANN WILLIAM D', 'HAEDICKE MARK E', 'BOWEN JR RAYMOND M', 'GILLIS JOHN', 'FITZGERALD JAY L', 'MORAN MICHAEL P', 'REDMOND BRIAN L', 'BAZELIDES PHILIP J', 'BELDEN TIMOTHY N', 'DURAN WILLIAM D', 'THORN TERENCE H', 'FASTOW ANDREW S', 'FOY JOE', 'CALGER CHRISTOPHER F', 'RICE KENNETH D', 'KAMINSKI WINCENTY J', 'LOCKHART EUGENE E', 'COX DAVID', 'OVERDYKE JR JERE C', 'PEREIRA PAULO V. FERRAZ', 'STABLER FRANK', 'SKILLING JEFFREY K', 'BLAKE JR. NORMAN P', 'SHERRICK JEFFREY B', 'PRENTICE JAMES', 'GRAY RODNEY', 'PICKERING MARK R', 'THE TRAVEL AGENCY IN THE PARK', 'NOLES JAMES L', 'KEAN STEVEN J', 'TOTAL', 'FOWLER PEGGY', 'WASAFF GEORGE', 'WHITE JR THOMAS E', 'CHRISTODOULOU DIOMEDES', 'ALLEN PHILLIP K', 'SHARP VICTORIA T', 'JAEDICKE ROBERT', 'WINOKUR JR. HERBERT S', 'BROWN MICHAEL', 'BADUM JAMES P', 'HUGHES JAMES A', 'REYNOLDS LAWRENCE', 'DIMICHELE RICHARD G', 'BHATNAGAR SANJAY', 'CARTER REBECCA C', 'BUCHANAN HAROLD G', 'YEAP SOON', 'MURRAY JULIA H', 'GARLAND C KEVIN', 'DODSON KEITH', 'YEAGER F SCOTT', 'HIRKO JOSEPH', 'DIETRICH JANET R', 'DERRICK JR. JAMES V', 'FREVERT MARK A', 'PAI LOU L', 'BAY FRANKLIN R', 'HAYSLETT RODERICK J', 'FUGH JOHN L', 'FALLON JAMES B', 'KOENIG MARK E', 'SAVAGE FRANK', 'IZZO LAWRENCE L', 'TILNEY ELIZABETH A', 'MARTIN AMANDA K', 'BUY RICHARD B', 'GRAMM WENDY L', 'CAUSEY RICHARD A', 'TAYLOR MITCHELL S', 'DONAHUE JR JEFFREY M', 'GLISAN JR BEN F']\n",
      "A typical key:value list:  {'salary': 1111258, 'to_messages': 3627, 'deferral_payments': 'NaN', 'total_payments': 8682716, 'exercised_stock_options': 19250000, 'bonus': 5600000, 'restricted_stock': 6843672, 'shared_receipt_with_poi': 2042, 'restricted_stock_deferred': 'NaN', 'total_stock_value': 26093672, 'expenses': 29336, 'loan_advances': 'NaN', 'from_messages': 108, 'other': 22122, 'from_this_person_to_poi': 30, 'poi': True, 'director_fees': 'NaN', 'deferred_income': 'NaN', 'long_term_incentive': 1920000, 'email_address': 'jeff.skilling@enron.com', 'from_poi_to_this_person': 88}\n"
     ]
    }
   ],
   "source": [
    "#total individuals\n",
    "print \"There are \", len(data_dict.keys()), \"executives of interest in the Enron dataset\"\n",
    "#number of pois\n",
    "num_poi = 0\n",
    "for dic in data_dict.values():\n",
    "    if dic['poi'] == 1: \n",
    "        num_poi += 1\n",
    "print \"There are \", num_poi, \"identified persons of interest within the dataset\"\n",
    "print \"Data Dictionary Keys:\"\n",
    "print(data_dict.keys())\n",
    "#data dictionary format\n",
    "print \"A typical key:value list: \", data_dict[\"SKILLING JEFFREY K\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see from this brief exploration that there are 146 exectives in the dataset, 18 identified POIs, and 22 features, for a total of 3088 observations. There are also a number of missing values. I'll investigate those in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA and Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values for each feature:\n",
      "bonus                         64\n",
      "deferral_payments            107\n",
      "deferred_income               97\n",
      "director_fees                129\n",
      "email_address                 35\n",
      "exercised_stock_options       44\n",
      "expenses                      51\n",
      "from_messages                 60\n",
      "from_poi_to_this_person       60\n",
      "from_this_person_to_poi       60\n",
      "loan_advances                142\n",
      "long_term_incentive           80\n",
      "other                         53\n",
      "poi                            0\n",
      "restricted_stock              36\n",
      "restricted_stock_deferred    128\n",
      "salary                        51\n",
      "shared_receipt_with_poi       60\n",
      "to_messages                   60\n",
      "total_payments                21\n",
      "total_stock_value             20\n",
      "dtype: int64\n",
      "Shape of the dataframe:  (146, 21)\n"
     ]
    }
   ],
   "source": [
    "#change dataset to pandas dataframe\n",
    "df = pandas.DataFrame.from_records(list(data_dict.values()))\n",
    "employees = pandas.Series(list(data_dict.keys()))\n",
    "\n",
    "#count number of NA values\n",
    "df.replace(to_replace='NaN', value=numpy.nan, inplace=True)\n",
    "print \"Number of NaN values for each feature:\"\n",
    "print df.isnull().sum()\n",
    "print \"Shape of the dataframe: \", df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a lot of NaN values for some of the features. Particularly loan advances, director fees, restricted stock deferred, and deferral payments. However, when I look at the data schema provided (enron61702insiderpay.pdf), I see that these \"missing values\" are actually 0, so I will convert them to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.333474e+06</td>\n",
       "      <td>4.387965e+05</td>\n",
       "      <td>-3.827622e+05</td>\n",
       "      <td>1.942249e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.182736e+06</td>\n",
       "      <td>7.074827e+04</td>\n",
       "      <td>358.602740</td>\n",
       "      <td>38.226027</td>\n",
       "      <td>24.287671</td>\n",
       "      <td>...</td>\n",
       "      <td>6.646839e+05</td>\n",
       "      <td>5.854318e+05</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>1.749257e+06</td>\n",
       "      <td>2.051637e+04</td>\n",
       "      <td>3.658114e+05</td>\n",
       "      <td>692.986301</td>\n",
       "      <td>1221.589041</td>\n",
       "      <td>4.350622e+06</td>\n",
       "      <td>5.846018e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.094029e+06</td>\n",
       "      <td>2.741325e+06</td>\n",
       "      <td>2.378250e+06</td>\n",
       "      <td>1.190543e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.607040e+07</td>\n",
       "      <td>4.327163e+05</td>\n",
       "      <td>1441.259868</td>\n",
       "      <td>73.901124</td>\n",
       "      <td>79.278206</td>\n",
       "      <td>...</td>\n",
       "      <td>4.046072e+06</td>\n",
       "      <td>3.682345e+06</td>\n",
       "      <td>0.329899</td>\n",
       "      <td>1.089995e+07</td>\n",
       "      <td>1.439661e+06</td>\n",
       "      <td>2.203575e+06</td>\n",
       "      <td>1072.969492</td>\n",
       "      <td>2226.770637</td>\n",
       "      <td>2.693448e+07</td>\n",
       "      <td>3.624681e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>-2.799289e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>-7.576788e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.792600e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.115000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.394475e+04</td>\n",
       "      <td>2.288695e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.082935e+05</td>\n",
       "      <td>2.018200e+04</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.595000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.605280e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.105960e+05</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>9.413595e+05</td>\n",
       "      <td>9.659550e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>9.684500e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.714221e+06</td>\n",
       "      <td>5.374075e+04</td>\n",
       "      <td>51.250000</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.750648e+05</td>\n",
       "      <td>1.506065e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.145280e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.708505e+05</td>\n",
       "      <td>893.500000</td>\n",
       "      <td>1585.750000</td>\n",
       "      <td>1.968287e+06</td>\n",
       "      <td>2.319991e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.734362e+07</td>\n",
       "      <td>3.208340e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.398517e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.117640e+08</td>\n",
       "      <td>5.235198e+06</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.852193e+07</td>\n",
       "      <td>4.266759e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.303223e+08</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>2.670423e+07</td>\n",
       "      <td>5521.000000</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>3.098866e+08</td>\n",
       "      <td>4.345095e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              bonus  deferral_payments  deferred_income  director_fees  \\\n",
       "count  1.460000e+02       1.460000e+02     1.460000e+02   1.460000e+02   \n",
       "mean   1.333474e+06       4.387965e+05    -3.827622e+05   1.942249e+04   \n",
       "std    8.094029e+06       2.741325e+06     2.378250e+06   1.190543e+05   \n",
       "min    0.000000e+00      -1.025000e+05    -2.799289e+07   0.000000e+00   \n",
       "25%    0.000000e+00       0.000000e+00    -3.792600e+04   0.000000e+00   \n",
       "50%    3.000000e+05       0.000000e+00     0.000000e+00   0.000000e+00   \n",
       "75%    8.000000e+05       9.684500e+03     0.000000e+00   0.000000e+00   \n",
       "max    9.734362e+07       3.208340e+07     0.000000e+00   1.398517e+06   \n",
       "\n",
       "       email_address  exercised_stock_options      expenses  from_messages  \\\n",
       "count          146.0             1.460000e+02  1.460000e+02     146.000000   \n",
       "mean             0.0             4.182736e+06  7.074827e+04     358.602740   \n",
       "std              0.0             2.607040e+07  4.327163e+05    1441.259868   \n",
       "min              0.0             0.000000e+00  0.000000e+00       0.000000   \n",
       "25%              0.0             0.000000e+00  0.000000e+00       0.000000   \n",
       "50%              0.0             6.082935e+05  2.018200e+04      16.500000   \n",
       "75%              0.0             1.714221e+06  5.374075e+04      51.250000   \n",
       "max              0.0             3.117640e+08  5.235198e+06   14368.000000   \n",
       "\n",
       "       from_poi_to_this_person  from_this_person_to_poi        ...          \\\n",
       "count               146.000000               146.000000        ...           \n",
       "mean                 38.226027                24.287671        ...           \n",
       "std                  73.901124                79.278206        ...           \n",
       "min                   0.000000                 0.000000        ...           \n",
       "25%                   0.000000                 0.000000        ...           \n",
       "50%                   2.500000                 0.000000        ...           \n",
       "75%                  40.750000                13.750000        ...           \n",
       "max                 528.000000               609.000000        ...           \n",
       "\n",
       "       long_term_incentive         other         poi  restricted_stock  \\\n",
       "count         1.460000e+02  1.460000e+02  146.000000      1.460000e+02   \n",
       "mean          6.646839e+05  5.854318e+05    0.123288      1.749257e+06   \n",
       "std           4.046072e+06  3.682345e+06    0.329899      1.089995e+07   \n",
       "min           0.000000e+00  0.000000e+00    0.000000     -2.604490e+06   \n",
       "25%           0.000000e+00  0.000000e+00    0.000000      8.115000e+03   \n",
       "50%           0.000000e+00  9.595000e+02    0.000000      3.605280e+05   \n",
       "75%           3.750648e+05  1.506065e+05    0.000000      8.145280e+05   \n",
       "max           4.852193e+07  4.266759e+07    1.000000      1.303223e+08   \n",
       "\n",
       "       restricted_stock_deferred        salary  shared_receipt_with_poi  \\\n",
       "count               1.460000e+02  1.460000e+02               146.000000   \n",
       "mean                2.051637e+04  3.658114e+05               692.986301   \n",
       "std                 1.439661e+06  2.203575e+06              1072.969492   \n",
       "min                -7.576788e+06  0.000000e+00                 0.000000   \n",
       "25%                 0.000000e+00  0.000000e+00                 0.000000   \n",
       "50%                 0.000000e+00  2.105960e+05               102.500000   \n",
       "75%                 0.000000e+00  2.708505e+05               893.500000   \n",
       "max                 1.545629e+07  2.670423e+07              5521.000000   \n",
       "\n",
       "        to_messages  total_payments  total_stock_value  \n",
       "count    146.000000    1.460000e+02       1.460000e+02  \n",
       "mean    1221.589041    4.350622e+06       5.846018e+06  \n",
       "std     2226.770637    2.693448e+07       3.624681e+07  \n",
       "min        0.000000    0.000000e+00      -4.409300e+04  \n",
       "25%        0.000000    9.394475e+04       2.288695e+05  \n",
       "50%      289.000000    9.413595e+05       9.659550e+05  \n",
       "75%     1585.750000    1.968287e+06       2.319991e+06  \n",
       "max    15149.000000    3.098866e+08       4.345095e+08  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace missing values with 0\n",
    "df.replace(to_replace=numpy.nan, value=0, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pairplot to visualize feature distributions\n",
    "def splom_viz(df, labels=None):\n",
    "    ax = sns.pairplot(df, hue=\"poi\", diag_kind='kde', size=2, vars=['poi','salary', 'total_payments', 'bonus', \n",
    "                 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', \n",
    "                 'restricted_stock', 'to_messages', 'from_poi_to_this_person', 'from_messages',\n",
    "                 'from_this_person_to_poi', 'shared_receipt_with_poi'])\n",
    "    plt.show()\n",
    "\n",
    "splom_viz(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this data, there definitely appears to be outliers. If I look at the data dictionary keys again, I see that there are two that are not names: Total and travel agency in the park. I'll remove these then look again at the pairplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#outlier removal\n",
    "df_subset = df.drop(df.index[[data_dict.keys().index(\"TOTAL\"), data_dict.keys().index(\"THE TRAVEL AGENCY IN THE PARK\")]])\n",
    "df_subset.describe()\n",
    "\n",
    "#pairplot to visualize distributions and correllations\n",
    "splom_viz(df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these outliers are removed, I can see on the pairplot that the most of the remainder of the outliers are classified as POI, so these \"outliers\" are in fact real data. The exception to this are the features 'from_poi_to_this_person', 'from_this_person_to_poi', and 'from_messages'. Looking at the statistics above, we see that the max 'from_messages' is 14368, which is one order of magnitude higher than the 75%. The same is true for the outliers in the other two categories.  Who are these people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max from_poi_to_this_person:  LAVORATO JOHN J\n",
      "Max from_this_person_to_poi:  DELAINEY DAVID W\n",
      "Max from_messages:  KAMINSKI WINCENTY J\n"
     ]
    }
   ],
   "source": [
    "#identify keys for potential outliers\n",
    "for key, value in data_dict.items():\n",
    "    if value['from_poi_to_this_person'] != 'NaN' and value['from_poi_to_this_person'] > 500: \n",
    "        print \"Max from_poi_to_this_person: \", key\n",
    "\n",
    "for key, value in data_dict.items():\n",
    "    if value['from_this_person_to_poi'] != 'NaN' and value['from_this_person_to_poi'] > 500: \n",
    "        print \"Max from_this_person_to_poi: \", key\n",
    "        \n",
    "for key, value in data_dict.items():\n",
    "    if value['from_messages'] != 'NaN' and value['from_messages'] > 14000: \n",
    "        print \"Max from_messages: \", key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these keys are all different people, I will keep the email data and assume it is real. Finally, looking at the pairplots and statistics for each feature, there are negative values for deferred_income, defferal_payments, restricted_stock, and restricted_stock deferred. Are these outliers, real data, or errors in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking financial features\n",
    "\n",
    "One final check we can do is make sure there aren't any mistakes in the financial data. In the data schema, we can see that two features: total_payments and total_stock_value are linear combinations of the other financial features. If the negative values observed above are real, then total_payments and total_stock_value should equal the sum of the values these features. If there is an error in the dataset, then these values will not be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Provided to give you a starting point. Try a variety of classifiers.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
